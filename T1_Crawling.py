import requests
from bs4 import BeautifulSoup
from pymongo import MongoClient
import html
import re  # Th∆∞ vi·ªán x·ª≠ l√Ω regex

# K·∫øt n·ªëi MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client.books_db
collection = db.books

BASE_URL = "https://books.toscrape.com/"

def get_categories():
    """L·∫•y danh s√°ch URL c·ªßa t·∫•t c·∫£ th·ªÉ lo·∫°i s√°ch t·ª´ sidebar"""
    response = requests.get(BASE_URL)
    if response.status_code != 200:
        print("‚ùå Kh√¥ng th·ªÉ truy c·∫≠p trang ch·ªß")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    categories = []

    for category in soup.select(".side_categories ul li ul li a"):
        category_name = category.text.strip()
        category_url = BASE_URL + category["href"]
        categories.append((category_name, category_url))

    return categories

def clean_text(text):
    """Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i, ch·ªØ s·ªë v√† d·∫•u c√°ch"""
    text = html.unescape(text)  # Gi·∫£i m√£ HTML entity (&quot; -> ")
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)  # Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† d·∫•u c√°ch
    return text.strip()

def get_book_details(book_url):
    """L·∫•y th√¥ng tin m√¥ t·∫£ v√† th·ªÉ lo·∫°i t·ª´ trang chi ti·∫øt s√°ch"""
    try:
        response = requests.get(book_url, timeout=10)
        if response.status_code != 200:
            print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu t·ª´ {book_url} (HTTP {response.status_code})")
            return {"description": "No description available"}

        soup = BeautifulSoup(response.text, "html.parser")

        # L·∫•y m√¥ t·∫£ s√°ch t·ª´ ph·∫ßn Product Description
        description_tag = soup.select_one("meta[name='description']")
        description = description_tag["content"].strip() if description_tag else "No description available"

        # L√†m s·∫°ch description ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
        description = clean_text(description)

        return {"description": description}

    except requests.exceptions.RequestException as e:
        print(f"üö® L·ªói khi l·∫•y {book_url}: {e}")
        return {"description": "No description available"}

def crawl_books():
    """Duy·ªát qua t·ª´ng th·ªÉ lo·∫°i s√°ch v√† l·∫•y d·ªØ li·ªáu s√°ch t·ª´ ƒë√≥"""
    categories = get_categories()
    if not categories:
        print("‚ùå Kh√¥ng t√¨m th·∫•y danh m·ª•c n√†o!")
        return

    for genre, genre_url in categories:
        print(f"üìö ƒêang qu√©t th·ªÉ lo·∫°i: {genre}")

        page = 1
        while True:
            url = genre_url.replace("index.html", f"page-{page}.html") if page > 1 else genre_url
            response = requests.get(url)
            if response.status_code != 200:
                break  # Kh√¥ng c√≤n trang ti·∫øp theo

            soup = BeautifulSoup(response.text, "html.parser")
            books = []

            for article in soup.find_all("article"):
                title = article.h3.a.attrs['title']
                price = article.select_one(".price_color").text.replace('√Ç', '').replace('¬£', '').strip()
                rate = article.p.attrs["class"][1]
                
                # L·∫•y ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c t·ª´ href
                relative_url = article.h3.a.attrs["href"]
                book_url = BASE_URL + "catalogue/" + relative_url.replace("../", "")

                # Chuy·ªÉn ƒë·ªïi rating t·ª´ ch·ªØ sang s·ªë
                rating_dict = {"One": 1, "Two": 2, "Three": 3, "Four": 4, "Five": 5}
                rate = rating_dict.get(rate, 0)

                # L·∫•y th√¥ng tin chi ti·∫øt
                details = get_book_details(book_url)

                book = {
                    "title": title,
                    "price": float(price),
                    "rate": float(rate),
                    "genre": genre,
                    "description": details["description"]
                }
                books.append(book)

            if books:
                collection.insert_many(books)
                print(f"‚úÖ ƒê√£ l∆∞u {len(books)} s√°ch t·ª´ th·ªÉ lo·∫°i '{genre}', trang {page}")

            page += 1  # Chuy·ªÉn sang trang ti·∫øp theo

    print("‚úÖ Ho√†n th√†nh qu√©t to√†n b·ªô s√°ch!")

if __name__ == "__main__":
    crawl_books()
